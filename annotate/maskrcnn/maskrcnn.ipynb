{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "rootdir = '/home/lscsc/caizhijie/0420-wamera-benchmark/data/pic'\n",
    "\n",
    "# \n",
    "import glob\n",
    "jpgs = glob.glob('%s/*/*.jpg' % rootdir)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "df_jpgs = pd.DataFrame.from_dict({'jpg': jpgs})\n",
    "\n",
    "df_jpgs['env'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[0][-1])\n",
    "df_jpgs['subj'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[1][-1])\n",
    "df_jpgs['group'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[2][-1])\n",
    "df_jpgs['angle'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[3][-1])\n",
    "df_jpgs['cam'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[4][-1])\n",
    "df_jpgs['t'] = df_jpgs['jpg'].apply(lambda x: x.split('_')[5][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jpg</th>\n",
       "      <th>env</th>\n",
       "      <th>subj</th>\n",
       "      <th>group</th>\n",
       "      <th>angle</th>\n",
       "      <th>cam</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292306</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292307</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292308</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292309</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292310</th>\n",
       "      <td>/home/lscsc/caizhijie/0420-wamera-benchmark/da...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292311 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      jpg env subj group  \\\n",
       "0       /home/lscsc/caizhijie/0420-wamera-benchmark/da...   1    2     2   \n",
       "1       /home/lscsc/caizhijie/0420-wamera-benchmark/da...   1    2     2   \n",
       "2       /home/lscsc/caizhijie/0420-wamera-benchmark/da...   1    2     2   \n",
       "3       /home/lscsc/caizhijie/0420-wamera-benchmark/da...   1    2     2   \n",
       "4       /home/lscsc/caizhijie/0420-wamera-benchmark/da...   1    2     2   \n",
       "...                                                   ...  ..  ...   ...   \n",
       "292306  /home/lscsc/caizhijie/0420-wamera-benchmark/da...   0    5     0   \n",
       "292307  /home/lscsc/caizhijie/0420-wamera-benchmark/da...   0    5     0   \n",
       "292308  /home/lscsc/caizhijie/0420-wamera-benchmark/da...   0    5     0   \n",
       "292309  /home/lscsc/caizhijie/0420-wamera-benchmark/da...   0    5     0   \n",
       "292310  /home/lscsc/caizhijie/0420-wamera-benchmark/da...   0    5     0   \n",
       "\n",
       "       angle cam  t  \n",
       "0          0   3  3  \n",
       "1          0   3  3  \n",
       "2          0   3  3  \n",
       "3          0   3  3  \n",
       "4          0   3  3  \n",
       "...      ...  .. ..  \n",
       "292306     3   2  3  \n",
       "292307     3   2  3  \n",
       "292308     3   2  3  \n",
       "292309     3   2  3  \n",
       "292310     3   2  3  \n",
       "\n",
       "[292311 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jpgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lscsc/caizhijie/miniconda3/envs/mtmd/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# df_jpgs\n",
    "\n",
    "# %%\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "\n",
    "yamlfile = 'configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'\n",
    "# yamlfile = 'configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml'\n",
    "\n",
    "cfg.merge_from_file(yamlfile)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(yamlfile[11:])\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(yamlfile[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class _dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    imgs = [cv2.imread(_['jpg']) for _ in batch]\n",
    "    paths = [_['jpg'] for _ in batch]\n",
    "    return np.stack(imgs), paths\n",
    "\n",
    "\n",
    "class packPredictor(DefaultPredictor):\n",
    "    def __call__(self, pack):\n",
    "        # 'NHWC'\n",
    "        assert len(pack.shape) == 4, 'A default predictor is qualified'\n",
    "        with torch.no_grad():\n",
    "            packimage = list()\n",
    "            packheight = list()\n",
    "            packwidth = list()\n",
    "            \n",
    "            for i in range(pack.shape[0]):\n",
    "                thisimage = pack[i, ...]\n",
    "                if self.input_format == 'RGB':\n",
    "                    thisimage = thisimage[..., ::-1]\n",
    "                    \n",
    "                # print(thisimage.shape)\n",
    "                height, width = thisimage.shape[:2]\n",
    "                image = self.aug.get_transform(thisimage).apply_image(thisimage)\n",
    "                image = torch.as_tensor(image.astype('float32').transpose(2, 0, 1))\n",
    "                \n",
    "                packimage.append(image)\n",
    "                packheight.append(height)\n",
    "                packwidth.append(width)\n",
    "            \n",
    "            inputs = [{'image': packimage[_], 'height': packheight[_], 'width': packwidth[_]} for _ in range(len(packimage))]\n",
    "            predictions = self.model(inputs)\n",
    "            return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/625 [00:19<1:40:54,  9.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m namelist \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39menumerate\u001b[39m(inference_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(inference_loader)):\n\u001b[0;32m---> 13\u001b[0m     output \u001b[39m=\u001b[39m ppredictor(batch[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     15\u001b[0m     dump \u001b[39m=\u001b[39m [_[\u001b[39m'\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m output]\n\u001b[1;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dump)):\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mpackPredictor.__call__\u001b[0;34m(self, pack)\u001b[0m\n\u001b[1;32m     45\u001b[0m     packwidth\u001b[39m.\u001b[39mappend(width)\n\u001b[1;32m     47\u001b[0m inputs \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: packimage[_], \u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m: packheight[_], \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m: packwidth[_]} \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(packimage))]\n\u001b[0;32m---> 48\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(inputs)\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/modeling/meta_arch/rcnn.py:150\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m        \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(batched_inputs)\n\u001b[1;32m    152\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batched_inputs[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/modeling/meta_arch/rcnn.py:204\u001b[0m, in \u001b[0;36mGeneralizedRCNN.inference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    203\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[0;32m--> 204\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(images\u001b[39m.\u001b[39;49mtensor)\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m detected_instances \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproposal_generator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/modeling/backbone/fpn.py:139\u001b[0m, in \u001b[0;36mFPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    127\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m        input (dict[str->Tensor]): mapping feature map name (e.g., \"res5\") to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m            [\"p2\", \"p3\", ..., \"p6\"].\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     bottom_up_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbottom_up(x)\n\u001b[1;32m    140\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[1;32m    141\u001b[0m     prev_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlateral_convs[\u001b[39m0\u001b[39m](bottom_up_features[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/modeling/backbone/resnet.py:449\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m     outputs[\u001b[39m\"\u001b[39m\u001b[39mstem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m x\n\u001b[1;32m    448\u001b[0m \u001b[39mfor\u001b[39;00m name, stage \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage_names, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages):\n\u001b[0;32m--> 449\u001b[0m     x \u001b[39m=\u001b[39m stage(x)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_features:\n\u001b[1;32m    451\u001b[0m         outputs[name] \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/modeling/backbone/resnet.py:195\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 195\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    196\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu_(out)\n\u001b[1;32m    198\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ref-rep/detectron2/detectron2/layers/wrappers.py:127\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    122\u001b[0m                 \u001b[39m# https://github.com/pytorch/pytorch/issues/12013\u001b[39;00m\n\u001b[1;32m    123\u001b[0m                 \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    124\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSyncBatchNorm\n\u001b[1;32m    125\u001b[0m                 ), \u001b[39m\"\u001b[39m\u001b[39mSyncBatchNorm does not support empty inputs!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 127\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m    128\u001b[0m     x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "openpose_dstrootdir = '/home/lscsc/caizhijie/0420-wamera-benchmark/data/openpose/'\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for k in range(4):\n",
    "    dataset = _dataset(df_jpgs[k * 20000:(k + 1) * 20000])\n",
    "    inference_loader = DataLoader(dataset, 32, shuffle=False, collate_fn=collate_fn, num_workers=8, pin_memory=True)\n",
    "    ppredictor = packPredictor(cfg)\n",
    "    \n",
    "    outputlist = list()\n",
    "    namelist = list()\n",
    "    for i, batch in tqdm.tqdm(enumerate(inference_loader), total=len(inference_loader)):\n",
    "        output = ppredictor(batch[0])\n",
    "        \n",
    "        dump = [_['instances'].to('cpu').get_fields() for _ in output]\n",
    "\n",
    "        for j in dump:\n",
    "            j['pred_masks'] = F.interpolate(j['pred_masks'].unsqueeze(1).float(), scale_factor=0.05)\n",
    "        \n",
    "        outputlist.extend(dump)\n",
    "        \n",
    "        namelist.extend(batch[1])\n",
    "        \n",
    "    for i in tqdm.trange(len(namelist)):\n",
    "        try:\n",
    "            pk.dump(outputlist[i], open(openpose_dstrootdir + ('/'.join(namelist[i].split('/')[-3:])[:-4] + '.pk'), 'wb'))\n",
    "        except FileNotFoundError:\n",
    "            if not os.path.exists(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-2])):\n",
    "                os.mkdir(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-2]))\n",
    "            if not os.path.exists(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-1])):\n",
    "                os.mkdir(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-1]))\n",
    "            pk.dump(outputlist[i], open(openpose_dstrootdir + ('/'.join(namelist[i].split('/')[-3:])[:-4] + '.pk'), 'wb'))\n",
    "    \n",
    "    print(len(outputlist))\n",
    "    print(len(namelist))\n",
    "    del outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lscsc/caizhijie/miniconda3/envs/mtmd/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dump = [_['instances'].to('cpu').get_fields() for _ in output]\n",
    "\n",
    "import torch.nn.functional as F\n",
    "for j in dump:\n",
    "    j['pred_masks'] = F.interpolate(j['pred_masks'].unsqueeze(1).float(), scale_factor=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
