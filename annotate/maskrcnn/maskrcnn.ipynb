{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lscsc/caizhijie/miniconda3/envs/mtmd/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "rootdir = '/home/lscsc/caizhijie/shar-data/archive'\n",
    "\n",
    "# %%\n",
    "import glob\n",
    "jpgs = glob.glob('%s/*/*/*.jpg' % rootdir)\n",
    "pks = glob.glob('%s/*/*/*.pk_2_1' % rootdir)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "df_jpgs = pd.DataFrame.from_dict({'jpg': jpgs})\n",
    "df_jpgs['subdir'] = df_jpgs['jpg'].apply(lambda x: x.split('/')[-2])\n",
    "df_jpgs['dir'] = df_jpgs['jpg'].apply(lambda x: x.split('/')[-3])\n",
    "df_jpgs = df_jpgs[df_jpgs['subdir'].apply(lambda x: x[0] == 't')]\n",
    "\n",
    "df_jpgs['mov'] = df_jpgs['dir'].apply(lambda x: x.split('_')[2])\n",
    "df_jpgs['obj'] = df_jpgs['dir'].apply(lambda x: x.split('_')[3])\n",
    "df_jpgs['ang'] = df_jpgs['dir'].apply(lambda x: x.split('_')[4])\n",
    "df_jpgs['rep'] = df_jpgs['subdir'].apply(lambda x: x.split('_')[0].split('t')[-1])\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# df_jpgs\n",
    "\n",
    "# %%\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "\n",
    "yamlfile = 'configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'\n",
    "# yamlfile = 'configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml'\n",
    "\n",
    "cfg.merge_from_file(yamlfile)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(yamlfile[11:])\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(yamlfile[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class _dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    imgs = [cv2.imread(_['jpg']) for _ in batch]\n",
    "    paths = [_['jpg'] for _ in batch]\n",
    "    return np.stack(imgs), paths\n",
    "\n",
    "\n",
    "class packPredictor(DefaultPredictor):\n",
    "    def __call__(self, pack):\n",
    "        # 'NHWC'\n",
    "        assert len(pack.shape) == 4, 'A default predictor is qualified'\n",
    "        with torch.no_grad():\n",
    "            packimage = list()\n",
    "            packheight = list()\n",
    "            packwidth = list()\n",
    "            \n",
    "            for i in range(pack.shape[0]):\n",
    "                thisimage = pack[i, ...]\n",
    "                if self.input_format == 'RGB':\n",
    "                    thisimage = thisimage[..., ::-1]\n",
    "                    \n",
    "                # print(thisimage.shape)\n",
    "                height, width = thisimage.shape[:2]\n",
    "                image = self.aug.get_transform(thisimage).apply_image(thisimage)\n",
    "                image = torch.as_tensor(image.astype('float32').transpose(2, 0, 1))\n",
    "                \n",
    "                packimage.append(image)\n",
    "                packheight.append(height)\n",
    "                packwidth.append(width)\n",
    "            \n",
    "            inputs = [{'image': packimage[_], 'height': packheight[_], 'width': packwidth[_]} for _ in range(len(packimage))]\n",
    "            predictions = self.model(inputs)\n",
    "            return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "darkdir = '/home/lscsc/caizhijie/0420-wamera-benchmark/darktest/'\n",
    "jpglist = glob.glob(darkdir + '1*.jpg')\n",
    "df = pd.DataFrame.from_dict({'jpg': jpglist})\n",
    "\n",
    "inference_dataset = _dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "openpose_dstrootdir = '/home/lscsc/caizhijie/archive_0118/maskrcnn/'\n",
    "\n",
    "import os\n",
    "\n",
    "for k in range(4):\n",
    "    # dataset = _dataset(df_jpgs[k * 20000:(k + 1) * 20000])\n",
    "    dataset = _dataset(df)\n",
    "    inference_loader = DataLoader(dataset, 32, shuffle=False, collate_fn=collate_fn, num_workers=8, pin_memory=True)\n",
    "    ppredictor = packPredictor(cfg)\n",
    "    \n",
    "    outputlist = list()\n",
    "    namelist = list()\n",
    "    for i, batch in tqdm.tqdm(enumerate(inference_loader), total=len(inference_loader)):\n",
    "        output = ppredictor(batch[0])\n",
    "        outputlist.extend([_['instances'].to('cpu') for _ in output])\n",
    "        \n",
    "        # outputlist.extend([1 for _ in range(len(batch[0]))])\n",
    "        \n",
    "        namelist.extend(batch[1])\n",
    "        \n",
    "    # for i in tqdm.trange(len(namelist)):\n",
    "    #     try:\n",
    "    #         pk.dump(outputlist[i], open(openpose_dstrootdir + ('/'.join(namelist[i].split('/')[-3:])[:-4] + '.pk'), 'wb'))\n",
    "    #     except FileNotFoundError:\n",
    "    #         if not os.path.exists(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-2])):\n",
    "    #             os.mkdir(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-2]))\n",
    "    #         if not os.path.exists(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-1])):\n",
    "    #             os.mkdir(openpose_dstrootdir + '/'.join(namelist[i].split('/')[-3:-1]))\n",
    "    \n",
    "    print(len(outputlist))\n",
    "    print(len(namelist))\n",
    "    # del outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.get_fields()['pred_masks'].__len__() for _ in outputlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
